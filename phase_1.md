# SelecciÃ³n y JustificaciÃ³n del Modelo de IA

## ğŸ¯ 1. DescripciÃ³n General y Objetivos TÃ©cnicos

Asistente de IA (chatbot) para el sitio web de EcoMarket.

- **Objetivo Principal:** Automatizar la respuesta a consultas frecuentes de clientes sobre productos, polÃ­ticas y estado de pedidos.

- **Meta TÃ©cnica:** Desarrollar un servicio de backend robusto y de baja latencia que se conecte a un modelo de lenguaje grande (LLM) para generar respuestas precisas y contextualizadas.

## ğŸ› ï¸ 2. Stack TecnolÃ³gico y SelecciÃ³n de Modelo

### Modelo de IA Generativa

**Modelo:** Gemini 2.5 Flash lite

**Proveedor:** Google (a travÃ©s de la API de Vertex AI)

#### Â¿Por quÃ© este modelo?

- âš¡ **Velocidad:** EstÃ¡ optimizado para casos de uso de chat. El objetivo es una latencia de respuesta de extremo a extremo *< 2 segundos*.

- ğŸ’° **Costo:** El modelo de pago por uso es ideal para el presupuesto operativo (OpEx) y evita grandes costos iniciales (CapEx). Dado que no se cuenta con servidores propios y los expertos necesarios para administrar un proveedor en la nube sobre el cual desplegar el modelo.

- ğŸ§  **Ventana de Contexto de 1M de Tokens:** Permite usar una arquitectura *RAG* de forma muy simple y potente, metiendo documentos enteros en el *prompt* en lugar de aplicar estrategias complejas de *chunking* (divisiÃ³n de texto).

- ğŸ”’ **Privacidad:** La polÃ­tica de Google para esta API garantiza que nuestros datos (consultas de clientes, info de productos) no se usarÃ¡n para reentrenar sus modelos.

- âš ï¸ **DecisiÃ³n clave:** El **fine-tuning* es caro, lento y requiere un dataset masivo. Para garantizar un uso adecuado de los recursos de la empresa se dejara como un posible trabajo futuro en caso de ser requerido una mejora en la experiencia de uso. La arquitectura RAG con un modelo grande como *Gemini 2.5  flash lite* resulta mÃ¡s pertinente, dado en parte a que el modelo ya a sido previamente entrenado con una gran variaedad de casos, incluyendo el de preguntas y respuestas. Por lo tanto, es suficiente con darle el contexto y las instrucciones adecuadas para que responda de la forma adecuada.

## ğŸ—ï¸ 3. Arquitectura del Sistema: Retrieval-Augmented Generation (RAG)

El cerebro de nuestro asistente es un flujo RAG. Esto asegura que el modelo responda basÃ¡ndose Ãºnicamente en la informaciÃ³n de EcoMarket y no invente datos ("alucinaciones").

- ğŸ—¨ï¸ **Preguntas bÃ¡sicas:** El usuario generalmente realiza preguntas bÃ¡sicas que pueden ser fÃ¡cilmente respondidas con los documentos de la empresa. El sistema RAG permite encontrar la informaciÃ³n adecuada para dar contexto al modelo y generar la respuesta apropiada.

- â„¹ï¸ **InformaciÃ³n del producto:** De la misma forma que las preguntas relacionadas a la operaciÃ³n del negocio, la informaciÃ³n de los productos tambiÃ©n deben hacer parte del espacio de bÃºsqueda. De esta forma cualquier duda con respecto al producto en el que el cliente esta interesado se responderia rÃ¡pidamente, asegurando en mayor medida una compra potencial.

- ğŸ“¦ **Estado del pedido:** Se puede actualizar frecuentemente una base de datos con el estado de los pedidos, estos serÃ­an obtenidos en la recuperaciÃ³n para preguntas relacionadas. Sin embargo, pueden no estar completamente actualizados en todo momento, esto puede requierir un gran esfuerzo adicional, en especial si algÃºn detalle en especifico se obtiene por un tercero (como la ubicaciÃ³n exacta si el envÃ­o lo realizza una empresa especializada)

## ğŸ“ˆ 4. Escalabilidad

Al ser un servicio gestionado por Google, la infraestructura subyacente estÃ¡ diseÃ±ada para escalar automÃ¡ticamente a niveles de demanda masivos. Las Ãºnicas limitaciones son los lÃ­mites de tasa de la API (rate limits), que pueden ser aumentados segÃºn el plan contratado con el proveedor. La latencia se mantiene consistentemente baja incluso a gran escala. TambiÃ©n es posible ampliar en un futuro el acceso a informaciÃ³n de tiempo real del estado de un pedido por medio de *MCP*.

## ğŸ§© Facilidad de integraciÃ³n

Se integra a travÃ©s de una API REST estÃ¡ndar, compatible con cualquier stack tecnolÃ³gico moderno. Google proporciona robustos SDKs (Software Development Kits) para lenguajes populares como Python, Node.js y Go, junto con documentaciÃ³n extensa y herramientas como Google AI Studio para un prototipado rÃ¡pido.
